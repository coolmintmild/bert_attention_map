# bert_attention_map

This repository contains the data and code for the following paper: <br/><br/>

Lee, J., & Shin, J. A. (2023). Decoding BERTâ€™s Internal Processing of Garden-Path Structures through Attention Maps. Korean Journal of English Language and Linguistics, 23, 461-481.<br/><br/>


Please cite the paper if you use the resources in the repository.<br/>

(The code is adapted from Vig, J. (2019). A multiscale visualization of attention in the transformer model. arXiv preprint arXiv:1906.05714.)<br/><br/>

# Compatibility
torch 1.31.1<br/>
transformsers 4.27.2
